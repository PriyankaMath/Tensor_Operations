{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TensorFlow2_Basics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNksXuN9nq3EjHpzjsu7sA5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PriyankaMath/Tensor_Operations/blob/main/TensorFlow2_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Basic Tensor Operations including einsum operations in Tensorflow 2.0\n",
        "\n",
        "**Submitted By:** Priyanka Math"
      ],
      "metadata": {
        "id": "zltuEtP8Pc3j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing TensorFlow"
      ],
      "metadata": {
        "id": "Tu9y9e4OY0Vm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CAAuNqVAYHkY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create Tensors"
      ],
      "metadata": {
        "id": "js4EK4naZlEy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Here is a \"scalar\" or \"rank-0\" tensor . A scalar contains a single value, and no \"axes\"."
      ],
      "metadata": {
        "id": "X5iMuauObWjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This will be an int32 tensor by default; see \"dtype\" below.\n",
        "rank_0_tensor = tf.constant(4)\n",
        "print(rank_0_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk9DQloxZvQi",
        "outputId": "435cdd24-9ca5-44da-9c16-71a995537eef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(4, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will be an float32 tensor by default; see \"dtype\" below.\n",
        "rank_0_tensor = tf.constant(4.0)\n",
        "print(rank_0_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a01dd6b-81e8-49cf-f111-758e9d00ce18",
        "id": "17kRKBzzaAy1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(4.0, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A \"vector\" or \"rank-1\" tensor is like a list of values. A vector has one axis:"
      ],
      "metadata": {
        "id": "0v7wvLejbbDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make this a float tensor.\n",
        "rank_1_tensor = tf.constant([2.0, 3.0, 4.0])\n",
        "print(rank_1_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNO46hfraNLy",
        "outputId": "03347cdc-251a-43a1-c35e-881642d62e7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### A \"matrix\" or \"rank-2\" tensor has two axes:"
      ],
      "metadata": {
        "id": "z6nJSwqvcFQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to be specific, you can set the dtype (see below) at creation time\n",
        "rank_2_tensor = tf.constant([[1, 2],\n",
        "                             [3, 4],\n",
        "                             [5, 6]], dtype=tf.float16)\n",
        "print(rank_2_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UzAzY5DucGy5",
        "outputId": "c732e51b-fc59-4ec7-d150-4771b6524a94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]], shape=(3, 2), dtype=float16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensors may have more axes; here is a tensor with three axes:"
      ],
      "metadata": {
        "id": "DPQ5VSjLcVIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There can be an arbitrary number of\n",
        "# axes (sometimes called \"dimensions\")\n",
        "rank_3_tensor = tf.constant([\n",
        "  [[0, 1, 2, 3, 4],\n",
        "   [5, 6, 7, 8, 9]],\n",
        "  [[10, 11, 12, 13, 14],\n",
        "   [15, 16, 17, 18, 19]],\n",
        "  [[20, 21, 22, 23, 24],\n",
        "   [25, 26, 27, 28, 29]],])\n",
        "\n",
        "print(rank_3_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh_41zDacXGm",
        "outputId": "6c9abe49-3274-49ed-b324-7228bb51849d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### You can convert a tensor to a NumPy array either using np.array or the tensor.numpy method:"
      ],
      "metadata": {
        "id": "OqnVH9KLctBI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(rank_2_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w82IegqYcuaR",
        "outputId": "c4da64b9-74d6-484c-c9e5-748e93d58eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.],\n",
              "       [5., 6.]], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rank_2_tensor.numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6CDAQQ5c7r3",
        "outputId": "6b2994d8-fe3e-48c5-ef8b-70b011f7c08c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 2.],\n",
              "       [3., 4.],\n",
              "       [5., 6.]], dtype=float16)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ndarray = np.ones([3, 3])\n",
        "\n",
        "print(\"TensorFlow operations convert numpy arrays to Tensors automatically\")\n",
        "tensor = tf.multiply(ndarray, 42)\n",
        "print(tensor)\n",
        "\n",
        "\n",
        "print(\"And NumPy operations convert Tensors to numpy arrays automatically\")\n",
        "print(np.add(tensor, 1))\n",
        "\n",
        "print(\"The .numpy() method explicitly converts a Tensor to a numpy array\")\n",
        "print(tensor.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgEbrLTu3Rir",
        "outputId": "8fd69bd2-118f-4e3a-e05c-ef32893aa067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow operations convert numpy arrays to Tensors automatically\n",
            "tf.Tensor(\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]], shape=(3, 3), dtype=float64)\n",
            "And NumPy operations convert Tensors to numpy arrays automatically\n",
            "[[43. 43. 43.]\n",
            " [43. 43. 43.]\n",
            " [43. 43. 43.]]\n",
            "The .numpy() method explicitly converts a Tensor to a numpy array\n",
            "[[42. 42. 42.]\n",
            " [42. 42. 42.]\n",
            " [42. 42. 42.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors often contain floats and ints, but have many other types, including:\n",
        "*   complex numbers\n",
        "*   strings\n",
        "\n",
        "The base tf.Tensor class requires tensors to be \"rectangular\"---that is, along each axis, every element is the same size. \n",
        "\n",
        "Note: Specialized types of tensors that can handle different shapes: \n",
        "\n",
        "*   Ragged tensors\n",
        "*   Sparse tensors\n",
        "\n"
      ],
      "metadata": {
        "id": "8xsMfzE4e1F_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Basic math on tensors, including addition, element-wise multiplication, and matrix multiplication."
      ],
      "metadata": {
        "id": "VdYIzoeQfjNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.constant([[1, 2],\n",
        "                 [3, 4]])\n",
        "b = tf.constant([[1, 1],\n",
        "                 [1, 1]]) # Could have also said `tf.ones([2,2])`\n",
        "\n",
        "print(tf.add(a, b), \"\\n\")\n",
        "print(tf.multiply(a, b), \"\\n\")\n",
        "print(tf.matmul(a, b), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UsOBviq-fbk3",
        "outputId": "c5c2de73-ba20-4848-f6cb-9e240f500034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[3 3]\n",
            " [7 7]], shape=(2, 2), dtype=int32) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a + b, \"\\n\") # element-wise addition\n",
        "print(a * b, \"\\n\") # element-wise multiplication\n",
        "print(a @ b, \"\\n\") # matrix multiplication"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qIn642Ef7Y3",
        "outputId": "1a2f9264-9a97-483d-9145-b57e71a8c555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[2 3]\n",
            " [4 5]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[3 3]\n",
            " [7 7]], shape=(2, 2), dtype=int32) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Tensors are used in all kinds of operations (ops)."
      ],
      "metadata": {
        "id": "ay2MshYRgM0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
        "\n",
        "# Find the largest value\n",
        "print(tf.reduce_max(c))\n",
        "\n",
        "# Find the index of the largest value\n",
        "print(tf.argmax(c))\n",
        "\n",
        "# Compute the softmax\n",
        "print(tf.nn.softmax(c))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPFDQQ0qgPq4",
        "outputId": "072f0f7f-8620-4493-ca68-332c70489e4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(10.0, shape=(), dtype=float32)\n",
            "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[2.6894143e-01 7.3105860e-01]\n",
            " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.reduce_sum([1, 2, 3]))\n",
        "\n",
        "# Operator overloading is also supported\n",
        "print(tf.square(2) + tf.square(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HhOAWFy2vKk",
        "outputId": "180ab99e-692c-42ac-b917-7f67ab43cca1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(6, shape=(), dtype=int32)\n",
            "tf.Tensor(13, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor Shapes"
      ],
      "metadata": {
        "id": "2yIGTPg8hDO8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors have shapes. Some vocabulary:\n",
        "\n",
        "*   **Shape:** The length (number of elements) of each of the axes of a tensor.\n",
        "*   **Rank:** Number of tensor axes. A scalar has rank 0, a vector has rank 1, a matrix is rank 2.\n",
        "*   **Axis or Dimension:** A particular dimension of a tensor.\n",
        "*   **Size:** The total number of items in the tensor, the product shape vector.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CbQUZlgmhT5e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensors and tf.TensorShape objects have convenient properties for accessing these:"
      ],
      "metadata": {
        "id": "mPUVW7VtiEAc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_4_tensor = tf.zeros([3, 2, 4, 5])"
      ],
      "metadata": {
        "id": "CNZEw-8UiFSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Type of every element:\", rank_4_tensor.dtype)\n",
        "print(\"Number of axes:\", rank_4_tensor.ndim)\n",
        "print(\"Shape of tensor:\", rank_4_tensor.shape)\n",
        "print(\"Elements along axis 0 of tensor:\", rank_4_tensor.shape[0])\n",
        "print(\"Elements along the last axis of tensor:\", rank_4_tensor.shape[-1])\n",
        "print(\"Total number of elements (3*2*4*5): \", tf.size(rank_4_tensor).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED9IxHhGiM59",
        "outputId": "6b0f6c74-2665-4656-c973-d6772dfc3185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of every element: <dtype: 'float32'>\n",
            "Number of axes: 4\n",
            "Shape of tensor: (3, 2, 4, 5)\n",
            "Elements along axis 0 of tensor: 3\n",
            "Elements along the last axis of tensor: 5\n",
            "Total number of elements (3*2*4*5):  120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While axes are often referred to by their indices, you should always keep track of the meaning of each. Often axes are ordered from global to local: The batch axis first, followed by spatial dimensions, and features for each location last. This way feature vectors are contiguous regions of memory.\n",
        "\n",
        "   Batch  Width   Height  Features\n",
        "[    3      2       4        5      ]"
      ],
      "metadata": {
        "id": "1BOPBW1VjiGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Indexing"
      ],
      "metadata": {
        "id": "l7iqZ1yMj9tC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Single-axis indexing"
      ],
      "metadata": {
        "id": "ngM-Gqj1kGNS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TensorFlow follows standard Python indexing rules, similar to indexing a list or a string in Python, and the basic rules for NumPy indexing.\n",
        "\n",
        "*   indexes start at 0\n",
        "*   negative indices count backwards from the end\n",
        "*   colons, :, are used for slices: start:stop:step"
      ],
      "metadata": {
        "id": "Rfipbew7kUAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rank_1_tensor = tf.constant([0, 1, 1, 2, 3, 5, 8, 13, 21, 34])\n",
        "print(rank_1_tensor.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GkQwnHnkJKl",
        "outputId": "a2197a89-3d5b-47f5-a0bd-e58547a6da8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  1  2  3  5  8 13 21 34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing with a scalar removes the axis:"
      ],
      "metadata": {
        "id": "sdHZj1bNkrkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"First:\", rank_1_tensor[0].numpy())\n",
        "print(\"Second:\", rank_1_tensor[1].numpy())\n",
        "print(\"Last:\", rank_1_tensor[-1].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at4N0-SlksgO",
        "outputId": "8529c70e-7478-4384-d8f5-7eef1ce6c6bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First: 0\n",
            "Second: 1\n",
            "Last: 34\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing with a : slice keeps the axis:"
      ],
      "metadata": {
        "id": "2Yo_FbIVk8Tk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Everything:\", rank_1_tensor[:].numpy())\n",
        "print(\"Before 4:\", rank_1_tensor[:4].numpy())\n",
        "print(\"From 4 to the end:\", rank_1_tensor[4:].numpy())\n",
        "print(\"From 2, before 7:\", rank_1_tensor[2:7].numpy())\n",
        "print(\"Every other item:\", rank_1_tensor[::2].numpy())\n",
        "print(\"Reversed:\", rank_1_tensor[::-1].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQnFKckqk8_B",
        "outputId": "e66ffe1e-d24f-4454-82dd-20f47da1084c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything: [ 0  1  1  2  3  5  8 13 21 34]\n",
            "Before 4: [0 1 1 2]\n",
            "From 4 to the end: [ 3  5  8 13 21 34]\n",
            "From 2, before 7: [1 2 3 5 8]\n",
            "Every other item: [ 0  1  3  8 21]\n",
            "Reversed: [34 21 13  8  5  3  2  1  1  0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-axis indexing"
      ],
      "metadata": {
        "id": "69-sGH8ClUyF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Higher rank tensors are indexed by passing multiple indices.\n",
        "\n",
        "The exact same rules as in the single-axis case apply to each axis independently."
      ],
      "metadata": {
        "id": "QLr0N7XbldKy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rank_2_tensor.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_E2oi_Qglry1",
        "outputId": "0cfbde9d-d859-46f5-92db-3a40c692579a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 2.]\n",
            " [3. 4.]\n",
            " [5. 6.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Passing an integer for each index, the result is a scalar."
      ],
      "metadata": {
        "id": "ARI8x5UulunQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pull out a single value from a 2-rank tensor\n",
        "print(rank_2_tensor[1, 1].numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Eh9NXOnlvZT",
        "outputId": "b7cbcf37-7c2e-4646-c7d9-ea2156a73b60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can index using any combination of integers and slices:"
      ],
      "metadata": {
        "id": "Q6Or3eakl3GV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get row and column tensors\n",
        "print(\"Second row:\", rank_2_tensor[1, :].numpy())\n",
        "print(\"Second column:\", rank_2_tensor[:, 1].numpy())\n",
        "print(\"Last row:\", rank_2_tensor[-1, :].numpy())\n",
        "print(\"First item in last column:\", rank_2_tensor[0, -1].numpy())\n",
        "print(\"Skip the first row:\")\n",
        "print(rank_2_tensor[1:, :].numpy(), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlupd5pPl39D",
        "outputId": "c3d81e79-26d2-49df-d473-ad939b83035b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Second row: [3. 4.]\n",
            "Second column: [2. 4. 6.]\n",
            "Last row: [5. 6.]\n",
            "First item in last column: 2.0\n",
            "Skip the first row:\n",
            "[[3. 4.]\n",
            " [5. 6.]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is an example with a 3-axis tensor:"
      ],
      "metadata": {
        "id": "cEXIIebomWbY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rank_3_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZfLN9Fgmn3s",
        "outputId": "f409665c-b4d4-46ea-c259-974723e549bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rank_3_tensor[:, :, 4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0AKrRTdmXKZ",
        "outputId": "77a69654-f122-40cb-ea19-1e72c990f334"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 4  9]\n",
            " [14 19]\n",
            " [24 29]], shape=(3, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Manipulating Shapes"
      ],
      "metadata": {
        "id": "iC1XTq26nAWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping a tensor is of great utility."
      ],
      "metadata": {
        "id": "b2GplXLpnKQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape returns a `TensorShape` object that shows the size along each axis\n",
        "x = tf.constant([[1], [2], [3]])\n",
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-NtrLwa2nMI2",
        "outputId": "7dbabd77-2fda-4ab4-aad3-f786420935c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# You can convert this object into a Python list, too\n",
        "print(x.shape.as_list())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0SSaNtunsm9",
        "outputId": "dd46b27a-8b56-4f3c-90a2-18c25dd2b434"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can reshape a tensor into a new shape. The tf.reshape operation is fast and cheap as the underlying data does not need to be duplicated."
      ],
      "metadata": {
        "id": "NoGQkGVrn1Cy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can reshape a tensor to a new shape.\n",
        "# Note that you're passing in a list\n",
        "reshaped = tf.reshape(x, [1, 3])"
      ],
      "metadata": {
        "id": "AX5JrPWZn3zR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "print(reshaped.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RbydxLjoCxx",
        "outputId": "09ee9d45-b363-4bb5-83a5-5c5ec0c999e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3, 1)\n",
            "(1, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data maintains its layout in memory and a new tensor is created, with the requested shape, pointing to the same data. TensorFlow uses C-style \"row-major\" memory ordering, where incrementing the rightmost index corresponds to a single step in memory."
      ],
      "metadata": {
        "id": "kyDJJstwoegl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(rank_3_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW-TrvH2ofIj",
        "outputId": "6f91fdf4-9c82-4c49-874e-38c500840d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]\n",
            "\n",
            " [[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(3, 2, 5), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you flatten a tensor you can see what order it is laid out in memory."
      ],
      "metadata": {
        "id": "1UVG_ipEokP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A `-1` passed in the `shape` argument says \"Whatever fits\".\n",
        "print(tf.reshape(rank_3_tensor, [-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlQ3XF7SomCX",
        "outputId": "0ce60978-f3fa-49e4-f3b2-be677ce9a18d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29], shape=(30,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Typically the only reasonable use of tf.reshape is to combine or split adjacent axes (or add/remove 1s).\n",
        "\n",
        "For this 3x2x5 tensor, reshaping to (3x2)x5 or 3x(2x5) are both reasonable things to do, as the slices do not mix:"
      ],
      "metadata": {
        "id": "vh43qmNJo8qC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.reshape(rank_3_tensor, [3*2, 5]), \"\\n\")\n",
        "print(tf.reshape(rank_3_tensor, [3, -1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Rm81wMMo_Eg",
        "outputId": "9d58edad-30cf-46ef-a1eb-cc9030911c34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4]\n",
            " [ 5  6  7  8  9]\n",
            " [10 11 12 13 14]\n",
            " [15 16 17 18 19]\n",
            " [20 21 22 23 24]\n",
            " [25 26 27 28 29]], shape=(6, 5), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5  6  7  8  9]\n",
            " [10 11 12 13 14 15 16 17 18 19]\n",
            " [20 21 22 23 24 25 26 27 28 29]], shape=(3, 10), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reshaping will \"work\" for any new shape with the same total number of elements, but it will not do anything useful if you do not respect the order of the axes.\n",
        "\n",
        "Swapping axes in **tf.reshape** does not work; you need **tf.transpose** for that."
      ],
      "metadata": {
        "id": "HfQofPb9qA7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bad examples: don't do this\n",
        "\n",
        "# You can't reorder axes with reshape.\n",
        "print(tf.reshape(rank_3_tensor, [2, 3, 5]), \"\\n\") \n",
        "\n",
        "# This is a mess\n",
        "print(tf.reshape(rank_3_tensor, [5, 6]), \"\\n\")\n",
        "\n",
        "# This doesn't work at all\n",
        "try:\n",
        "  tf.reshape(rank_3_tensor, [7, -1])\n",
        "except Exception as e:\n",
        "  print(f\"{type(e).__name__}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qBe7k8aqCLu",
        "outputId": "23c92a8f-081a-4369-81be-83e62d49ff31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]\n",
            "  [10 11 12 13 14]]\n",
            "\n",
            " [[15 16 17 18 19]\n",
            "  [20 21 22 23 24]\n",
            "  [25 26 27 28 29]]], shape=(2, 3, 5), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 0  1  2  3  4  5]\n",
            " [ 6  7  8  9 10 11]\n",
            " [12 13 14 15 16 17]\n",
            " [18 19 20 21 22 23]\n",
            " [24 25 26 27 28 29]], shape=(5, 6), dtype=int32) \n",
            "\n",
            "InvalidArgumentError: Input to reshape is a tensor with 30 values, but the requested shape requires a multiple of 7 [Op:Reshape]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DTypes:"
      ],
      "metadata": {
        "id": "Zhi0UImrr6GQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To inspect a tf.Tensor's data type use the Tensor.dtype property.\n",
        "\n",
        "When creating a tf.Tensor from a Python object you may optionally specify the datatype.\n",
        "\n",
        "If you don't, TensorFlow chooses a datatype that can represent your data. TensorFlow converts Python integers to tf.int32 and Python floating point numbers to tf.float32. Otherwise TensorFlow uses the same rules NumPy uses when converting to arrays.\n",
        "\n",
        "You can cast from type to type."
      ],
      "metadata": {
        "id": "HHTeK-I3sHCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "the_f64_tensor = tf.constant([2.2, 3.3, 4.4], dtype=tf.float64)\n",
        "the_f16_tensor = tf.cast(the_f64_tensor, dtype=tf.float16)\n",
        "# Now, cast to an uint8 and lose the decimal precision\n",
        "the_u8_tensor = tf.cast(the_f16_tensor, dtype=tf.uint8)\n",
        "print(the_u8_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-GJ6c0wnsINu",
        "outputId": "05eb1b19-61f3-4f03-f145-55535f0de9e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 3 4], shape=(3,), dtype=uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Broadcasting"
      ],
      "metadata": {
        "id": "D8qa5owjtBrw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Broadcasting is a concept borrowed from the equivalent feature in NumPy. In short, under certain conditions, smaller tensors are \"stretched\" automatically to fit larger tensors when running combined operations on them.\n",
        "\n",
        "The simplest and most common case is when you attempt to multiply or add a tensor to a scalar. In that case, the scalar is broadcast to be the same shape as the other argument."
      ],
      "metadata": {
        "id": "Ny-1wPh0tuBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.constant([1, 2, 3])\n",
        "\n",
        "y = tf.constant(2)\n",
        "z = tf.constant([2, 2, 2])\n",
        "# All of these are the same computation\n",
        "print(tf.multiply(x, 2))\n",
        "print(x * y)\n",
        "print(x * z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFqGkDyRtu3v",
        "outputId": "65f64b94-b88a-49aa-b1d5-6e27b0634aa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n",
            "tf.Tensor([2 4 6], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Likewise, axes with length 1 can be stretched out to match the other arguments. Both arguments can be stretched in the same computation.\n",
        "\n",
        "In this case a 3x1 matrix is element-wise multiplied by a 1x4 matrix to produce a 3x4 matrix. Note how the leading 1 is optional: The shape of y is [4]."
      ],
      "metadata": {
        "id": "MMEBIumXuoA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# These are the same computations\n",
        "x = tf.reshape(x,[3,1])\n",
        "y = tf.range(1, 5)\n",
        "print(x, \"\\n\")\n",
        "print(y, \"\\n\")\n",
        "print(tf.multiply(x, y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ojKp8EAuoy0",
        "outputId": "5c32ad88-8eec-49bc-aa88-119e223ce77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1]\n",
            " [2]\n",
            " [3]], shape=(3, 1), dtype=int32) \n",
            "\n",
            "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32) \n",
            "\n",
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here is the same operation without broadcasting:"
      ],
      "metadata": {
        "id": "M6a8iqjjvLH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_stretch = tf.constant([[1, 1, 1, 1],\n",
        "                         [2, 2, 2, 2],\n",
        "                         [3, 3, 3, 3]])\n",
        "\n",
        "y_stretch = tf.constant([[1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4],\n",
        "                         [1, 2, 3, 4]])\n",
        "\n",
        "print(x_stretch * y_stretch)  # Again, operator overloading"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tH_ba5FvLpI",
        "outputId": "56f31450-617b-4608-d281-265db4ca97ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 1  2  3  4]\n",
            " [ 2  4  6  8]\n",
            " [ 3  6  9 12]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You see what broadcasting looks like using tf.broadcast_to."
      ],
      "metadata": {
        "id": "kvh-eKrCvhBT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.broadcast_to(tf.constant([1, 2, 3]), [3, 3]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Sx9kr1Gvjse",
        "outputId": "c892a0a0-f533-461e-99f9-2d02d117e953"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2 3]\n",
            " [1 2 3]\n",
            " [1 2 3]], shape=(3, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ragged Tensors"
      ],
      "metadata": {
        "id": "VL64cAVdvu7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A tensor with variable numbers of elements along some axis is called \"ragged\". Use tf.ragged.RaggedTensor for ragged data.\n",
        "\n",
        "For example, This cannot be represented as a regular tensor:\n",
        "\n"
      ],
      "metadata": {
        "id": "gnvlauZmwzIF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ragged_list = [\n",
        "    [0, 1, 2, 3],\n",
        "    [4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9]]"
      ],
      "metadata": {
        "id": "g7oQwhPTw1wr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "  tensor = tf.constant(ragged_list)\n",
        "except Exception as e:\n",
        "  print(f\"{type(e).__name__}: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhGoPQu4w5Hh",
        "outputId": "ada06d5f-5e91-40c8-9312-e6a0c807b73f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ValueError: Can't convert non-rectangular Python sequence to Tensor.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead create a tf.RaggedTensor using tf.ragged.constant:"
      ],
      "metadata": {
        "id": "DZPZWOt4w8us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ragged_tensor = tf.ragged.constant(ragged_list)\n",
        "print(ragged_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg_IFljtw9fM",
        "outputId": "8766fcf1-fda8-4793-9ec8-fc74a8bea559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The shape of a tf.RaggedTensor will contain some axes with unknown lengths:"
      ],
      "metadata": {
        "id": "FWnV9K-fxERB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(ragged_tensor.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhU4BMg4xE1S",
        "outputId": "23f97433-da3f-4664-bf8a-b622d21ed898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## String tensors"
      ],
      "metadata": {
        "id": "mhr5wcP1xMHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tf.string is a dtype, which is to say you can represent data as strings (variable-length byte arrays) in tensors.\n",
        "\n",
        "The strings are atomic and cannot be indexed the way Python strings are. The length of the string is not one of the axes of the tensor. \n",
        "\n",
        "Here is a scalar string tensor:"
      ],
      "metadata": {
        "id": "60VGYMFixWFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensors can be strings, too here is a scalar string.\n",
        "scalar_string_tensor = tf.constant(\"Gray wolf\")\n",
        "print(scalar_string_tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nsnWcd-PyAvq",
        "outputId": "adcfca69-02ec-4e65-c39a-39d2f22a6dec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Gray wolf', shape=(), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "And a vector of strings:"
      ],
      "metadata": {
        "id": "YJmrBO0kx-xQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If you have three string tensors of different lengths, this is OK.\n",
        "tensor_of_strings = tf.constant([\"Gray wolf\",\n",
        "                                 \"Quick brown fox\",\n",
        "                                 \"Lazy dog\"])\n",
        "# Note that the shape is (3,). The string length is not included.\n",
        "print(tensor_of_strings)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdo4-bXZyL3R",
        "outputId": "7cf31e9d-2bae-43c8-8808-2133c9b9463c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'Gray wolf' b'Quick brown fox' b'Lazy dog'], shape=(3,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the above printout the b prefix indicates that tf.string dtype is not a unicode string, but a byte-string."
      ],
      "metadata": {
        "id": "f7luMqeYyZku"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some basic functions with strings can be found in **tf.strings**, including tf.strings.split."
      ],
      "metadata": {
        "id": "P-IfTIV-ylsC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can use split to split a string into a set of tensors\n",
        "print(tf.strings.split(scalar_string_tensor, sep=\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohQ0bBLpymWz",
        "outputId": "e258c7bf-693e-48eb-fbfd-8a94d4033dd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([b'Gray' b'wolf'], shape=(2,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ...but it turns into a `RaggedTensor` if you split up a tensor of strings,\n",
        "# as each string might be split into a different number of parts.\n",
        "print(tf.strings.split(tensor_of_strings))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7dlV1eMoy3_R",
        "outputId": "dfa2bc19-9ed0-4f7a-e809-68d730700563"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<tf.RaggedTensor [[b'Gray', b'wolf'], [b'Quick', b'brown', b'fox'], [b'Lazy', b'dog']]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.string.to_number:**"
      ],
      "metadata": {
        "id": "2zQwPZ13zAqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = tf.constant(\"1 10 100\")\n",
        "print(tf.strings.to_number(tf.strings.split(text, \" \")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vd9RP-slzDoX",
        "outputId": "3df6a65a-f0ca-4610-e1ec-53c952a8f8c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([  1.  10. 100.], shape=(3,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although you can't use tf.cast to turn a string tensor into numbers, you can convert it into bytes, and then into numbers."
      ],
      "metadata": {
        "id": "1d_J4_92zRkv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "byte_strings = tf.strings.bytes_split(tf.constant(\"Duck\"))\n",
        "byte_ints = tf.io.decode_raw(tf.constant(\"Duck\"), tf.uint8)\n",
        "print(\"Byte strings:\", byte_strings)\n",
        "print(\"Bytes:\", byte_ints)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZvwzN6RzVLB",
        "outputId": "0b4a901d-a2fd-499a-9f8f-fed6530b810f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Byte strings: tf.Tensor([b'D' b'u' b'c' b'k'], shape=(4,), dtype=string)\n",
            "Bytes: tf.Tensor([ 68 117  99 107], shape=(4,), dtype=uint8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Or split it up as unicode and then decode it\n",
        "unicode_bytes = tf.constant(\"アヒル 🦆\")\n",
        "unicode_char_bytes = tf.strings.unicode_split(unicode_bytes, \"UTF-8\")\n",
        "unicode_values = tf.strings.unicode_decode(unicode_bytes, \"UTF-8\")\n",
        "\n",
        "print(\"\\nUnicode bytes:\", unicode_bytes)\n",
        "print(\"\\nUnicode chars:\", unicode_char_bytes)\n",
        "print(\"\\nUnicode values:\", unicode_values)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzwFd-52zwsz",
        "outputId": "ff6b67d3-0691-4b30-cc0c-c2a0940f641a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Unicode bytes: tf.Tensor(b'\\xe3\\x82\\xa2\\xe3\\x83\\x92\\xe3\\x83\\xab \\xf0\\x9f\\xa6\\x86', shape=(), dtype=string)\n",
            "\n",
            "Unicode chars: tf.Tensor([b'\\xe3\\x82\\xa2' b'\\xe3\\x83\\x92' b'\\xe3\\x83\\xab' b' ' b'\\xf0\\x9f\\xa6\\x86'], shape=(5,), dtype=string)\n",
            "\n",
            "Unicode values: tf.Tensor([ 12450  12498  12523     32 129414], shape=(5,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sparse tensors"
      ],
      "metadata": {
        "id": "2zh7Pacp0AY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sometimes, your data is sparse, like a very wide embedding space. TensorFlow supports tf.sparse.SparseTensor and related operations to store sparse data efficiently."
      ],
      "metadata": {
        "id": "R6fcd9470KYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sparse tensors store values by index in a memory-efficient manner\n",
        "sparse_tensor = tf.sparse.SparseTensor(indices=[[0, 0], [1, 2]],\n",
        "                                       values=[1, 2],\n",
        "                                       dense_shape=[3, 4])\n",
        "print(sparse_tensor, \"\\n\")\n",
        "\n",
        "# You can convert sparse tensors to dense\n",
        "print(tf.sparse.to_dense(sparse_tensor))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAZgOJrt0PfW",
        "outputId": "7388b921-9106-48df-c003-b2ed02e1b134"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SparseTensor(indices=tf.Tensor(\n",
            "[[0 0]\n",
            " [1 2]], shape=(2, 2), dtype=int64), values=tf.Tensor([1 2], shape=(2,), dtype=int32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64)) \n",
            "\n",
            "tf.Tensor(\n",
            "[[1 0 0 0]\n",
            " [0 0 2 0]\n",
            " [0 0 0 0]], shape=(3, 4), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Datasets:"
      ],
      "metadata": {
        "id": "R24IrO8N4WHQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This section uses the tf.data.Dataset API to build a pipeline for feeding data to your model. The tf.data.Dataset API is used to build performant, complex input pipelines from simple, re-usable pieces that will feed your model's training or evaluation loops."
      ],
      "metadata": {
        "id": "M42oRdst4Xql"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zI0fmOynH-Ne"
      },
      "source": [
        "#### Create a source `Dataset`\n",
        "\n",
        "Create a *source* dataset using one of the factory functions like Dataset.from_tensors, Dataset.from_tensor_slices, or using objects that read from files like TextLineDataset or TFRecordDataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F04fVOHQIBiG"
      },
      "outputs": [],
      "source": [
        "ds_tensors = tf.data.Dataset.from_tensor_slices([1, 2, 3, 4, 5, 6])\n",
        "\n",
        "# Create a CSV file\n",
        "import tempfile\n",
        "_, filename = tempfile.mkstemp()\n",
        "\n",
        "with open(filename, 'w') as f:\n",
        "  f.write(\"\"\"Line 1\n",
        "Line 2\n",
        "Line 3\n",
        "  \"\"\")\n",
        "\n",
        "ds_file = tf.data.TextLineDataset(filename)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbxIhC-5IPdf"
      },
      "source": [
        "#### Apply transformations\n",
        "\n",
        "Use the transformations functions like [`map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map), [`batch`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#batch), and [`shuffle`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#shuffle) to apply transformations to dataset records."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uXSDZWE-ISsd"
      },
      "outputs": [],
      "source": [
        "ds_tensors = ds_tensors.map(tf.square).shuffle(2).batch(2)\n",
        "\n",
        "ds_file = ds_file.batch(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8X1GNfoIZKJ"
      },
      "source": [
        "### Iterate\n",
        "\n",
        "`tf.data.Dataset` objects support iteration to loop over records:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ws-WKRk5Ic6-",
        "outputId": "505666bf-87b3-4e11-ceb5-328dd764a68d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elements of ds_tensors:\n",
            "tf.Tensor([1 9], shape=(2,), dtype=int32)\n",
            "tf.Tensor([16 25], shape=(2,), dtype=int32)\n",
            "tf.Tensor([ 4 36], shape=(2,), dtype=int32)\n",
            "\n",
            "Elements in ds_file:\n",
            "tf.Tensor([b'Line 1' b'Line 2'], shape=(2,), dtype=string)\n",
            "tf.Tensor([b'Line 3' b'  '], shape=(2,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "print('Elements of ds_tensors:')\n",
        "for x in ds_tensors:\n",
        "  print(x)\n",
        "\n",
        "print('\\nElements in ds_file:')\n",
        "for x in ds_file:\n",
        "  print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Einsum Operations"
      ],
      "metadata": {
        "id": "nBVHm0dG9Tmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Matrix Multiplication"
      ],
      "metadata": {
        "id": "RujoHG6H9h0a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m0 = tf.constant(\n",
        "  [[ 1, 2],\n",
        "   [3, 4]])\n",
        "m1 = tf.constant(\n",
        "    [[1, 2],\n",
        "     [3, 4]]\n",
        ")\n",
        "x = tf.einsum('ij,jk->ik', m0, m1)\n",
        "# output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
        "print(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJ2JUnCc9qmt",
        "outputId": "6856675a-79ec-45d7-b7e9-cfb14c5e928b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 7 10]\n",
            " [15 22]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** If the output indices are not specified repeated indices are summed. So ij,jk->ik can be simplified to ij,jk.\n",
        "Repeated indices are summed if the output indices are not specified."
      ],
      "metadata": {
        "id": "zCRvW7LQfL_f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.einsum('ij,jk', m0, m1)  # output[i,k] = sum_j m0[i,j] * m1[j, k]\n",
        "print(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW7363n8fMyx",
        "outputId": "f13c0653-9684-48f8-f17d-46f186226e6f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[ 7 10]\n",
            " [15 22]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dot product"
      ],
      "metadata": {
        "id": "Upno1napxK1S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = tf.constant([ 1, 2])\n",
        "v = tf.constant([ 3, 4])\n",
        "print(u)\n",
        "print(v)\n",
        "e = tf.einsum('i,i->', u, v)  # output = sum_i u[i]*v[i] (1*3 + 2*4)\n",
        "print(e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy_IsMayxNmU",
        "outputId": "ad7dac72-836c-410d-e8ad-f07e74a101c6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
            "tf.Tensor([3 4], shape=(2,), dtype=int32)\n",
            "tf.Tensor(11, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Outer product"
      ],
      "metadata": {
        "id": "lPTcmD0OyI3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = tf.constant([ 1, 2])\n",
        "v = tf.constant([ 3, 4, 5])\n",
        "print(u)\n",
        "print(v)\n",
        "e = tf.einsum('i,j->ij', u, v)  # output[i,j] = u[i]*v[j] \n",
        "print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpuGGZYryGlX",
        "outputId": "76c1a1fb-5cde-4ad8-dded-d0e2720e2800"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([1 2], shape=(2,), dtype=int32)\n",
            "tf.Tensor([3 4 5], shape=(3,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[ 3  4  5]\n",
            " [ 6  8 10]], shape=(2, 3), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transpose"
      ],
      "metadata": {
        "id": "2c_qPCr4zag9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m0 = tf.constant(\n",
        "  [[ 1, 2],\n",
        "   [3, 4]])\n",
        "print(m0)\n",
        "e = tf.einsum('ij->ji', m0)  # output[j,i] = m0[i,j]\n",
        "print(e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdsDKzy-zbOM",
        "outputId": "175a21bb-c037-4596-f756-34475e6f9c02"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[1 2]\n",
            " [3 4]], shape=(2, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[1 3]\n",
            " [2 4]], shape=(2, 2), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Diag"
      ],
      "metadata": {
        "id": "6tjzT7JB3mPf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = tf.reshape(tf.range(9), [3,3])\n",
        "print(m)\n",
        "diag = tf.einsum('ii->i', m)\n",
        "print(diag)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GP2pAB9J3pqd",
        "outputId": "264598e0-bbfb-42fd-d485-0cad91e63e77"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0 1 2]\n",
            " [3 4 5]\n",
            " [6 7 8]], shape=(3, 3), dtype=int32)\n",
            "tf.Tensor([0 4 8], shape=(3,), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trace"
      ],
      "metadata": {
        "id": "yYOpJ0Ao36wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeated indices are summed.\n",
        "trace = tf.einsum('ii', m)  # output[j,i] = trace(m) = sum_i m[i, i]\n",
        "assert trace == sum(diag)\n",
        "print(trace)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DENFUCHD3_1r",
        "outputId": "3bd839f5-4d8d-451e-d111-7b233bee28d6"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(12, shape=(), dtype=int32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Batch matrix multiplication"
      ],
      "metadata": {
        "id": "k75SkHS-N0yZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = tf.reshape(tf.range(60), [5, 4, 3])\n",
        "print(s)\n",
        "t = tf.reshape(tf.range(30), [5, 3, 2])\n",
        "print(t)\n",
        "e = tf.einsum('bij,bjk->bik', s, t)\n",
        "# output[a,i,k] = sum_j s[a,i,j] * t[a, j, k]\n",
        "print(e)\n",
        "print(s.shape)\n",
        "print(t.shape)\n",
        "print(e.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RL0bjNBr4YbF",
        "outputId": "397999e0-ef3e-4a97-9570-2b99bfc7f592"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2]\n",
            "  [ 3  4  5]\n",
            "  [ 6  7  8]\n",
            "  [ 9 10 11]]\n",
            "\n",
            " [[12 13 14]\n",
            "  [15 16 17]\n",
            "  [18 19 20]\n",
            "  [21 22 23]]\n",
            "\n",
            " [[24 25 26]\n",
            "  [27 28 29]\n",
            "  [30 31 32]\n",
            "  [33 34 35]]\n",
            "\n",
            " [[36 37 38]\n",
            "  [39 40 41]\n",
            "  [42 43 44]\n",
            "  [45 46 47]]\n",
            "\n",
            " [[48 49 50]\n",
            "  [51 52 53]\n",
            "  [54 55 56]\n",
            "  [57 58 59]]], shape=(5, 4, 3), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[[ 0  1]\n",
            "  [ 2  3]\n",
            "  [ 4  5]]\n",
            "\n",
            " [[ 6  7]\n",
            "  [ 8  9]\n",
            "  [10 11]]\n",
            "\n",
            " [[12 13]\n",
            "  [14 15]\n",
            "  [16 17]]\n",
            "\n",
            " [[18 19]\n",
            "  [20 21]\n",
            "  [22 23]]\n",
            "\n",
            " [[24 25]\n",
            "  [26 27]\n",
            "  [28 29]]], shape=(5, 3, 2), dtype=int32)\n",
            "tf.Tensor(\n",
            "[[[  10   13]\n",
            "  [  28   40]\n",
            "  [  46   67]\n",
            "  [  64   94]]\n",
            "\n",
            " [[ 316  355]\n",
            "  [ 388  436]\n",
            "  [ 460  517]\n",
            "  [ 532  598]]\n",
            "\n",
            " [[1054 1129]\n",
            "  [1180 1264]\n",
            "  [1306 1399]\n",
            "  [1432 1534]]\n",
            "\n",
            " [[2224 2335]\n",
            "  [2404 2524]\n",
            "  [2584 2713]\n",
            "  [2764 2902]]\n",
            "\n",
            " [[3826 3973]\n",
            "  [4060 4216]\n",
            "  [4294 4459]\n",
            "  [4528 4702]]], shape=(5, 4, 2), dtype=int32)\n",
            "(5, 4, 3)\n",
            "(5, 3, 2)\n",
            "(5, 4, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method does not support broadcasting on named-axes. All axes with matching labels should have the same length. If you have length-1 axes, use tf.squeseze or tf.reshape to eliminate them.\n",
        "\n",
        "To write code that is agnostic to the number of indices in the input use an ellipsis. The ellipsis is a placeholder for \"whatever other indices fit here\".\n",
        "\n",
        "For example, to perform a NumPy-style broadcasting-batch-matrix multiplication where the matrix multiply acts on the last two axes of the input, use:"
      ],
      "metadata": {
        "id": "c069GB-U8pQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = tf.random.normal(shape=[11, 7, 5, 3])\n",
        "t = tf.random.normal(shape=[11, 7, 3, 2])\n",
        "e =  tf.einsum('...ij,...jk->...ik', s, t)\n",
        "print(e.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO3bPeRc85-9",
        "outputId": "fae44927-6134-45b2-d1ce-9a924f62f42e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11, 7, 5, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Einsum will broadcast over axes covered by the ellipsis."
      ],
      "metadata": {
        "id": "G6jxfInF89Vt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = tf.random.normal(shape=[11, 1, 5, 3])\n",
        "t = tf.random.normal(shape=[1, 7, 3, 2])\n",
        "e =  tf.einsum('...ij,...jk->...ik', s, t)\n",
        "print(e.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JaShO-oS8-AL",
        "outputId": "1b927057-7050-414f-8108-061894977b4e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(11, 7, 5, 2)\n"
          ]
        }
      ]
    }
  ]
}